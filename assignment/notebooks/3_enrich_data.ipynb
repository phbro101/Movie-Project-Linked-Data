{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task: Enrich your dataset with additional data from DBpedia and WikiData \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Overview\n",
    "Use the newly found DBpedia and Wikidata resources and collect additional information from DBpedia and Wikidata on the movies. It is sufficient to reuse the DBpedia and Wikidata vocabulary and use directly the DBpedia property values (including when the value is a URL/IRI), e.g., it is enough if you include the following information from DBpedia on the gross value and the producer:\n",
    "\n",
    "<code>    \n",
    "PREFIX dbo: http://dbpedia.org/ontology/\n",
    "    \n",
    "<https://firstname-lastname.org/resource/the_godfather>  dbo:gross    2.541E8^^xsd:double;\n",
    "                                                       dbo:producer <http://dbpedia.org/page/Albert_S._Ruddy> .\n",
    "<code>\n",
    "    \n",
    "> __Hint__: Using SPARQLâ€™s OPTIONAL keyword might help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task Details\n",
    "\n",
    "1. Using SPARQL queries, information you __Must Get__ (if available in DBpedia and Wikidata for the movie):\n",
    "    - Get the distinct genre(s) of a movie\n",
    "    - Get the distinct actors \n",
    "    - Get the homepage of a movie\n",
    "    - Get the number of received awards\n",
    "    - Get the IMDB and the RottenTomatoes links\n",
    "    - Get the box office value/gross value\n",
    "    - Get the cost of a movie\n",
    "\n",
    "\n",
    "\n",
    "## Submission 3:\n",
    "\n",
    "Use RDFLib to load the data you have saved in Task 2 and add the additional information to the corresponding movies. As mentioned above, you can use the DBpedia and WikiData predicates. Save the enriched data set in the output folder with naming __movies_task_3.n3__.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "## Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import URIRef, Literal, Graph, Namespace\n",
    "from rdflib.namespace import FOAF, RDF, RDFS, XSD, DC, OWL\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, N3, RDFXML\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EX = Namespace(\"https://ex1.org/\")\n",
    "DBO = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "RSC = Namespace(\"http://philip-broehl.org/resource/\")\n",
    "WD = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "WDT = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "SCH = Namespace(\"https://schema.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450"
     ]
    }
   ],
   "source": [
    "# load graph from previous exercise\n",
    "g = Graph()\n",
    "g.load(source = \"../output_data/movies_task_2.n3\", format = 'n3')\n",
    "g.bind('dbo', DBO)\n",
    "g.bind(\"wd\", WD)\n",
    "g.bind(\"wdt\", WDT)\n",
    "\n",
    "# extract all sameAs links in Graph\n",
    "sameAs_db = []\n",
    "sameAs_wd = []\n",
    "for s in list(g.subjects(predicate = RDF.type, object = SCH.Movie)):\n",
    "    for sameAs in g.objects(subject = URIRef(s), predicate = OWL.sameAs):\n",
    "        if \"dbpedia\" in sameAs:\n",
    "            sameAs_db.append(sameAs)\n",
    "        else:\n",
    "            sameAs_wd.append(sameAs)\n",
    "\n",
    "# from dbpedia, we can get the budget, gross and starring actors\n",
    "query_db = \"\"\"\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    \n",
    "    CONSTRUCT { \n",
    "        ?movie dbo:budget ?budget ;\n",
    "            dbo:gross ?gross ;\n",
    "            dbo:starring ?actor .\n",
    "    }\n",
    "    WHERE {\n",
    "        ?movie rdf:type dbo:Film .\n",
    "        OPTIONAL { ?movie dbo:budget ?budget }\n",
    "        OPTIONAL { ?movie dbo:gross ?gross }\n",
    "        OPTIONAL { ?movie dbo:starring ?actor }\n",
    "        VALUES ?movie { \"\"\"\n",
    "\n",
    "# from wikidata, we can get the genre, official website, IMDb link, rottenTomatoes link and\n",
    "# number of awards.\n",
    "# wdt:P136 is genre, wdt:P856 is the official website, P345 is the IMDb link, P1258 is the\n",
    "# rottenTomatoes link, and P166 is award received.\n",
    "query_wd = \"\"\"\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "    CONSTRUCT {\n",
    "        ?movie wdt:P136 ?genre ;\n",
    "            wdt:P856 ?official_website ;\n",
    "            wdt:P345 ?IMDb_link ;\n",
    "            wdt:P1258 ?RottenTomatoes_link ;\n",
    "            wdt:P166 ?awards .\n",
    "    }\n",
    "    WHERE {\n",
    "        ?movie wdt:P31 wd:Q11424 .\n",
    "        OPTIONAL { ?movie wdt:P136 ?genre }\n",
    "        OPTIONAL { ?movie wdt:P856 ?official_website }\n",
    "        OPTIONAL { ?movie wdt:P345 ?IMDb_link }\n",
    "        OPTIONAL { ?movie wdt:P1258 ?RottenTomatoes_link }\n",
    "        OPTIONAL { ?movie wdt:P166 ?awards }\n",
    "        VALUES ?movie { \"\"\"\n",
    "\n",
    "results_db = []\n",
    "results_wd = []\n",
    "values = \"\"\n",
    "i = 0\n",
    "for uri in sameAs_db:\n",
    "    i += 1\n",
    "    print(f'\\r{i}', end = '')\n",
    "    values += \"<\" + str(uri) + \">\"\n",
    "    if i % 50 == 0 or i == len(sameAs_db):   \n",
    "        values += \"}\\n}\"\n",
    "        \n",
    "        sparql_db = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "        sparql_db.setQuery(query_db + values)\n",
    "        sparql_db.setReturnFormat(RDFXML)\n",
    "        results_db.append(sparql_db.query().convert())\n",
    "        values = \"\"\n",
    "\n",
    "for uri in sameAs_wd:\n",
    "    i += 1\n",
    "    print(f'\\r{i}', end = '')\n",
    "    values += \"<\" + str(uri) + \">\"\n",
    "    if i % 50 == 0 or i == len(sameAs_wd):   \n",
    "        values += \"}\\n}\"\n",
    "        sparql_wd = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "        sparql_wd.setQuery(query_wd + values)\n",
    "        sparql_wd.setReturnFormat(RDFXML)\n",
    "        results_wd.append(sparql_wd.query().convert())\n",
    "        \n",
    "        values = \"\"\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join graphs\n",
    "graph_db = Graph()\n",
    "graph_wd = Graph()\n",
    "\n",
    "for graph in results_db:\n",
    "    graph_db += graph\n",
    "for graph in results_wd:\n",
    "    graph_wd += graph\n",
    "    \n",
    "for s in list(g.subjects(predicate = RDF.type, object = SCH.Movie)):\n",
    "    sameAs_db = None\n",
    "    sameAs_wd = None\n",
    "    award_count = 0\n",
    "    for sameAs in g.objects(subject = URIRef(s), predicate = OWL.sameAs):\n",
    "        if \"dbpedia\" in sameAs:\n",
    "            sameAs_db = sameAs\n",
    "        else:\n",
    "            sameAs_wd = sameAs\n",
    "    if sameAs_db != None:\n",
    "        for (p, o) in list(graph_db.predicate_objects(sameAs_db)):\n",
    "            g.add((URIRef(s), p, o))\n",
    "    if sameAs_wd != None:\n",
    "        for (p, o) in list(graph_wd.predicate_objects(sameAs_wd)):\n",
    "            # form IMDb links and rottenTomatoes links from IDs (see formatter URL of properties)\n",
    "            # P1065 is the archive URL datatype, which is compatible with IMDB / rottenTomatoes IDs\n",
    "            if p == URIRef(\"http://www.wikidata.org/prop/direct/P345\"):\n",
    "                o = Literal(\"https://www.imdb.com/title/\" + str(o), datatype = WDT.P1065)\n",
    "            if p == URIRef(\"http://www.wikidata.org/prop/direct/P1258\"):\n",
    "                o = Literal(\"https://www.rottentomatoes.com/\" + str(o), datatype = WDT.P1065)\n",
    "            if p == URIRef(\"http://www.wikidata.org/prop/direct/P166\"):\n",
    "                award_count += 1\n",
    "                continue\n",
    "            g.add((URIRef(s), p, o))\n",
    "        # property P166 (received awards) also supports quantities (Q309314)\n",
    "        g.add((URIRef(s), WDT.P166, Literal(award_count, datatype = WD.Q309314)))\n",
    "        \n",
    "print(g.serialize(format=\"n3\").decode(\"utf-8\"))\n",
    "g.serialize(destination='../output_data/movies_task_3.n3', format='n3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_movies_with_sameAs = len(list(set(g.subjects(object = SCH.Movie)) & set(g.subjects(predicate = OWL.sameAs))))\n",
    "print(f'RottenTomatoes Links: {len(list(g.objects(predicate = WDT.P1258)))} / {number_movies_with_sameAs}')\n",
    "print(f'IMDb Links: {len(list(g.objects(predicate = WDT.P345)))} / {number_movies_with_sameAs}')\n",
    "print(f'Films with actors: {len(set(g.subjects(predicate = DBO.starring)))} / {number_movies_with_sameAs}')\n",
    "print(f'Films with budget: {len(set(g.subjects(predicate = DBO.budget)))} / {number_movies_with_sameAs}')\n",
    "print(f'Films with gross: {len(set(g.subjects(predicate = DBO.gross)))} / {number_movies_with_sameAs}')\n",
    "print(f'Films with genre: {len(set(g.subjects(predicate = WDT.P136)))} / {number_movies_with_sameAs}')\n",
    "print(f'Films with official website: {len(set(g.subjects(predicate = WDT.P856)))} / {number_movies_with_sameAs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
